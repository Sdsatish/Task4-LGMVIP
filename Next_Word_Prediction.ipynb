{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Next Word Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rHPiXWns8qsq"
      },
      "source": [
        "**LETSGROWWMORE**\n",
        "\n",
        "**Internship Period** : OCTOBER21\n",
        "\n",
        "**Task 2** : Preduction Using UnSupervised ML\n",
        "\n",
        "**NEXT Word Prediction Using RNN**\n",
        "\n",
        "Using Tensorflow and Keras library train a RNN, to predict the next word.\n",
        "\n",
        "**LEVEL** : ADVANCED LEVEL TASK\n",
        "\n",
        "**Author Name :** Satish Dixit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbVzAyJd_GXc"
      },
      "source": [
        "Importing all the required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sU_TBEiHUh1"
      },
      "source": [
        "from numpy import array\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Embedding\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRZlLDww_NZM"
      },
      "source": [
        "Using a dummy data for prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5S1kmudOHY7J"
      },
      "source": [
        "# Source Data\n",
        "\n",
        "data= \"\"\"Piford Technology is a leading Software Devlopment Company\\n\n",
        "Piford Technologies provided trainings to working professionals and students\\n\n",
        "we are product based and service based company\\n\n",
        "we have one of our office in IT Park,Mohali\\n\"\"\""
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaOMYlHEJsc3",
        "outputId": "faf976ba-04c0-42c3-cef4-93bb86eb72c3"
      },
      "source": [
        "# integer encode text\n",
        "token=Tokenizer()\n",
        "token.fit_on_texts([data])\n",
        "encoded_data=token.texts_to_sequences([data])[0]\n",
        "encoded_data[:5]"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRtKvmQBKOr6",
        "outputId": "7b797200-789a-43dc-e666-6938bad47589"
      },
      "source": [
        "vocab_size= len(token.word_index)+1\n",
        "\n",
        "print('vocablary size : %d'% vocab_size)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocablary size : 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLaFH_1W8nQA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRnPd3CAK7N2"
      },
      "source": [
        "# Next we need to create  sequences of words to fit the model with one word as input and one word as put\n"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUuz2Lh0LNrW",
        "outputId": "b4938249-aad9-4180-9489-e09bd860e823"
      },
      "source": [
        "#create word -> Sequence word\n",
        "\n",
        "sequences = list()\n",
        "for i in range(1,len(encoded_data)):\n",
        "  sequence=encoded_data[i-1:i+1]\n",
        "  sequences.append(sequence)\n",
        "print('Total Sequences : %d' %len(sequences))\n"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Sequences : 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10_0PSYYMHTC",
        "outputId": "32613beb-255a-490d-edf9-4badb0515444"
      },
      "source": [
        "#now  see how sequnces looks likes\n",
        "sequences[:6]"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 6], [6, 7], [7, 8], [8, 9], [9, 10], [10, 11]]"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IolTbysV_1-o"
      },
      "source": [
        " Now We Spliting this sequences into x and y"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IyaaP2BMPLJ"
      },
      "source": [
        "\n",
        "sequences  = array(sequences)\n",
        "x,y =sequences[:,0],sequences[:,1]"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNW9irbPNP60",
        "outputId": "c04ed121-9724-47b1-a3fb-27712ebe8c67"
      },
      "source": [
        "x[:5]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RxkivlPN7nD",
        "outputId": "fd612252-a7f8-4646-d583-6cff1901d2bb"
      },
      "source": [
        "y[:5]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFBoRlRsN9aR"
      },
      "source": [
        "#one hot encode outputss\n",
        "\n",
        "y= to_categorical(y,num_classes=vocab_size)\n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WQMLuMvABes"
      },
      "source": [
        "Now  We Select model ,compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hsK8Ea6OdJ0"
      },
      "source": [
        "# MOdel Selection\n",
        "model = Sequential()"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T-xYwTagal_",
        "outputId": "ca909960-18e7-4ae4-9cd9-97a8ff3e13d5"
      },
      "source": [
        "model.add(Embedding(vocab_size,10,input_length=1))\n",
        "model.add(LSTM(50))\n",
        "model.add(Dense(vocab_size,activation='softmax'))\n",
        "print(model.summary())"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 1, 10)             310       \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 50)                12200     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 31)                1581      \n",
            "=================================================================\n",
            "Total params: 14,091\n",
            "Trainable params: 14,091\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAw54XFtiCqx"
      },
      "source": [
        "#compile Network\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOHXJi9AjGXl",
        "outputId": "bda35a20-a900-482f-8a4a-edb90ce0b49a"
      },
      "source": [
        "model.fit(x,y,epochs=100)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 3.2035 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd1c4897050>"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7hsMQrHARwO"
      },
      "source": [
        "**Writing the function using RNN which is  predict the next word**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwXgfbcxncd8"
      },
      "source": [
        "\n",
        "#te a sequence from the model\n",
        "def generate_seq(model, token,enter_text, n_pred):\n",
        "  in_text,result=enter_text, enter_text\n",
        "\n",
        "  for _ in range(n_pred):\n",
        "\n",
        "    encoded=token.texts_to_sequences([in_text])[0]\n",
        "    encoded=array(encoded)\n",
        "    # predict the word in the vocabulary\n",
        "    #yhat=model.predict_classes(encoded)\n",
        "    yhat=model.predict(encoded)\n",
        "    classes_y=np.argmax(yhat,axis=1)\n",
        "    #print(classes_y)\n",
        "    #map predicted word index to word\n",
        "\n",
        "    out_word =\"\"\n",
        "    for word, index in token.word_index.items():\n",
        "      if index == classes_y:\n",
        "        out_word= word\n",
        "        break\n",
        "    in_text, result = out_word,result + ' ' +out_word\n",
        "  return result\n"
      ],
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMjkZtF_AkOU"
      },
      "source": [
        "Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKyQ7HKxjVTb",
        "outputId": "e0a7f9d6-87d0-43d7-8e6e-e3d7b2cd6715"
      },
      "source": [
        "#evaluate \n",
        "\n",
        "print(generate_seq(model,token, 'Piford',3))"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Piford technologies provided we\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnwL7Wwnq96p",
        "outputId": "6e5034b4-728d-427a-b16a-1a1cfd88d2c5"
      },
      "source": [
        "print(generate_seq(model,token, 'service',3))"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "service based and we\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug4t-lgG2TVF"
      },
      "source": [
        ""
      ],
      "execution_count": 199,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFB_jMyG46_p"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}